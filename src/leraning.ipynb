{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. 45. 48. ... nan nan nan]\n",
      "[23.65660438 20.34377235  9.47797052 ...         nan         nan\n",
      "         nan]\n",
      "[4.50000000e+01 4.80000000e+01 1.00000000e+00 4.00000000e+00\n",
      " 2.56774873e-19 2.56774873e-19 1.99122555e-12 1.69852219e+00]\n",
      "500\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 15ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 188/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: nan - mse: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 64\u001b[0m\n\u001b[0;32m     59\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     60\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     61\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     63\u001b[0m \u001b[39m#モデルの学習\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[0;32m     66\u001b[0m \u001b[39m#学習の様子をグラフに描画\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m#損失関数の値\u001b[39;00m\n\u001b[0;32m     68\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\Desktop\\python-fluid-python3\\soturon\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネルがクラッシュしました。エラーの原因を特定するには、セル内のコードを確認してください。詳細については、<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a> をクリックしてください。さらなる詳細については、Jupyter [log] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "#test.csvの9列目以降のデータから，8列目までのデータを予測する\n",
    "#dataframeで読み込み\n",
    "df = pd.read_csv('test3.csv', header=0,)\n",
    "\n",
    "#dataframeをnumpy配列に変換\n",
    "data = df.values\n",
    "\n",
    "#深層学習の入力データと出力データに分ける\n",
    "# 入力データ\n",
    "\n",
    "len_test = 8\n",
    "x = data[:, len_test+1:]\n",
    "print(x[0])\n",
    "\n",
    "# 出力データ\n",
    "y = data[:, 1:len_test+1]\n",
    "print(y[0])\n",
    "#入力データの正規化\n",
    "x = (x - x.mean()) / x.std()\n",
    "\n",
    "#出力データの正規化\n",
    "#y = (y - y.mean()) / y.std()\n",
    "\n",
    "#入力データの次元数\n",
    "input_dim = x.shape[1]\n",
    "\n",
    "#出力データの次元数\n",
    "output_dim = y.shape[1]\n",
    "\n",
    "#入力データの数\n",
    "n = x.shape[0]\n",
    "print(n)\n",
    "\n",
    "#学習データとテストデータに分ける\n",
    "#学習データ\n",
    "x_train = x[:int(n*0.8)]\n",
    "y_train = y[:int(n*0.8)]\n",
    "\n",
    "#テストデータ\n",
    "x_test = x[int(n*0.8):]\n",
    "y_test = y[int(n*0.8):]\n",
    "\n",
    "#モデルの定義\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    # ドロップアウト\n",
    " #   tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    #ドロップアウト\n",
    "   # tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "   # tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(output_dim)\n",
    "])\n",
    "\n",
    "#モデルのコンパイル\n",
    "model.compile(optimizer='adam',\n",
    "                loss='mse',\n",
    "                metrics=['mse'])\n",
    "\n",
    "#モデルの学習\n",
    "history = model.fit(x_train, y_train, epochs=1000, batch_size=32, validation_split=0.2)\n",
    "\n",
    "#学習の様子をグラフに描画\n",
    "#損失関数の値\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [MPG]')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "#表示\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータチューニング\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # ハイパーパラメータの探索範囲を定義\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    layers = []\n",
    "    for i in range(n_layers):\n",
    "        n_units = trial.suggest_int('n_units_l{}'.format(i), 4, 128)\n",
    "        layers.append(tf.keras.layers.Dense(n_units, activation='relu'))\n",
    "    layers.append(tf.keras.layers.Dense(output_dim))\n",
    "\n",
    "    model = tf.keras.models.Sequential(layers)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='mse',\n",
    "                metrics=['mae'])\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=10000, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "    return history.history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "[[nan nan nan nan nan nan nan nan]]\n",
      "[[  20.           24.           49.           31.         1599.23985289\n",
      "  1599.23985289 1626.21989027 1661.75029712]]\n"
     ]
    }
   ],
   "source": [
    "#1行目の値を実際に計算\n",
    "print(model.predict(x_test[:1]))\n",
    "#実際の値\n",
    "print(y_test[:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soturon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee786c526721bbce9e63e1da4cfab52b3e2151d0cb70578f4f93324897d70c1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
