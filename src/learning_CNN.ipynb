{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import tqdm\n",
    "import psutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_length(arr):\n",
    "    res = 0\n",
    "    for s in (0, 4):\n",
    "        res += ((arr[s] - arr[s + 2]) ** 2 +\n",
    "                (arr[s + 1] - arr[s + 3]) ** 2)\n",
    "    return res\n",
    "\n",
    "\n",
    "def min_length(arr):\n",
    "    res = 100\n",
    "    arr = arr[:8]\n",
    "    #numpyに\n",
    "    arr = np.array(arr)\n",
    "    for s in (0,4):\n",
    "        res = min(res, (arr[s] - arr[s + 2]) ** 2 +\n",
    "                  (arr[s + 1] - arr[s + 3]) ** 2)\n",
    "    print(f\"\\r{res}\",end=\"\")\n",
    "    return res\n",
    "\n",
    "def cherry_pick(df,threshold=10):\n",
    "    # data[:8]のmin_lengthが10未満のものをdrop\n",
    "    df = df.apply(lambda x: min_length(x) >= threshold, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"0118final\"\n",
    "for i in range(10):\n",
    "    filename = f\"{prefix}/{prefix}_{i}.csv\"\n",
    "    # csvファイルの読み込み\n",
    "    if i == 0:\n",
    "        df = pd.read_csv(filename, header=0)\n",
    "        df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    else:\n",
    "        tmp = pd.read_csv(filename, header=0)\n",
    "        tmp = tmp.drop(\"Unnamed: 0\", axis=1)\n",
    "        df = pd.concat([df, tmp], axis=0)\n",
    "\n",
    "#cherry_pick(df)\n",
    "\n",
    "\n",
    "#dataframeをnumpy配列に変換\n",
    "data = df.values\n",
    "#深層学習の入力データと出力データに分ける\n",
    "# 入力データ\n",
    "len_test = 8\n",
    "x = data[:, len_test:]\n",
    "\n",
    "#x[i]をN×Nに変換\n",
    "siz = 32\n",
    "x = x.reshape(-1, siz,siz)\n",
    "\n",
    "#xは現在グレースケールなので、RGBに変換\n",
    "x = np.stack((x,)*3, axis=-1)\n",
    "\n",
    "# 出力データ\n",
    "y = data[:, :len_test]\n",
    "#入力データの正規化\n",
    "x = (x - x.mean()) / x.std()\n",
    "\n",
    "#入力データの各行をN×Nに変換\n",
    "\n",
    "\n",
    "#出力データのMin-Max正規化\n",
    "y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "#入力データの次元数\n",
    "input_dim = x.shape[1]\n",
    "\n",
    "#出力データの次元数\n",
    "output_dim = y.shape[1]\n",
    "\n",
    "#入力データの数\n",
    "n = x.shape[0]\n",
    "\n",
    "#学習データとテストデータに分ける\n",
    "#学習データ\n",
    "x_train = x[:int(n*0.8)]\n",
    "y_train = y[:int(n*0.8)]\n",
    "\n",
    "#テストデータ\n",
    "x_test = x[int(n*0.8):]\n",
    "y_test = y[int(n*0.8):]\n",
    "\n",
    "\n",
    "N = siz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#optunaを使わないCNN\n",
    "def create_model(use_pretrained=False, CNN_size=0, trainable=True):\n",
    "    # モデルの定義\n",
    "    if use_pretrained:\n",
    "        weights = \"imagenet\"\n",
    "    else:\n",
    "        weights = None\n",
    "\n",
    "\n",
    "    cnn_models = [tf.keras.applications.efficientnet.EfficientNetB0,\n",
    "                tf.keras.applications.efficientnet.EfficientNetB1,\n",
    "                tf.keras.applications.efficientnet.EfficientNetB2,\n",
    "                tf.keras.applications.efficientnet.EfficientNetB3,\n",
    "                tf.keras.applications.efficientnet.EfficientNetB4,\n",
    "                tf.keras.applications.efficientnet.EfficientNetB5,\n",
    "                tf.keras.applications.efficientnet.EfficientNetB6,\n",
    "                tf.keras.applications.efficientnet.EfficientNetB7]\n",
    "\n",
    "    if CNN_size <= len(cnn_models):\n",
    "        base_model = cnn_models[CNN_size](\n",
    "            include_top=False,\n",
    "            weights=weights,\n",
    "            input_shape=(N, N, 3)\n",
    "        )\n",
    "\n",
    "    base_model.trainable = trainable\n",
    "\n",
    "\n",
    "    #学習済データは使用しない\n",
    "\n",
    "\n",
    "    #8個の出力を持つモデル\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(N, N, 3)),\n",
    "        base_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(8),\n",
    "    ])\n",
    "    \n",
    "    # モデルのコンパイル\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "#学習の実行\n",
    "def objective(use_pretrained=False, CNN_size=0, trainable=True):\n",
    "    model = create_model(use_pretrained, CNN_size, trainable=True)\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=500,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_test, y_test),\n",
    "    )\n",
    "    #学習の様子をプロット\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#片対数プロット\n",
    "def plot_and_save(history,filename):\n",
    "    #pltを初期化\n",
    "    plt.clf()\n",
    "    #plotを作成\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    #plotの上限を設定\n",
    "    plt.ylim(0, 0.1)\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    #軸ラベルを追加\n",
    "    ax.set_xlabel(\"epoch\")\n",
    "    ax.set_ylabel(\"loss\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 22s 60ms/step - loss: 0.2452 - mae: 0.3558 - val_loss: 0.1148 - val_mae: 0.2828\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0731 - mae: 0.2199 - val_loss: 0.1143 - val_mae: 0.2842\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0659 - mae: 0.2070 - val_loss: 0.0976 - val_mae: 0.2649\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0593 - mae: 0.1941 - val_loss: 0.0967 - val_mae: 0.2645\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0552 - mae: 0.1862 - val_loss: 0.0973 - val_mae: 0.2641\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0501 - mae: 0.1753 - val_loss: 0.1024 - val_mae: 0.2666\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0462 - mae: 0.1674 - val_loss: 0.1083 - val_mae: 0.2741\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0428 - mae: 0.1605 - val_loss: 0.1053 - val_mae: 0.2696\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.0397 - mae: 0.1536 - val_loss: 0.0921 - val_mae: 0.2530\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0377 - mae: 0.1493 - val_loss: 0.1191 - val_mae: 0.2852\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0348 - mae: 0.1431 - val_loss: 0.0952 - val_mae: 0.2559\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0330 - mae: 0.1385 - val_loss: 0.1184 - val_mae: 0.2844\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0305 - mae: 0.1331 - val_loss: 0.0665 - val_mae: 0.2071\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0284 - mae: 0.1286 - val_loss: 0.1364 - val_mae: 0.3027\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0275 - mae: 0.1266 - val_loss: 0.1034 - val_mae: 0.2616\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.0260 - mae: 0.1225 - val_loss: 0.1127 - val_mae: 0.2725\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.0249 - mae: 0.1202 - val_loss: 0.1160 - val_mae: 0.2796\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0245 - mae: 0.1193 - val_loss: 0.1214 - val_mae: 0.2854\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0233 - mae: 0.1166 - val_loss: 0.1032 - val_mae: 0.2558\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0230 - mae: 0.1159 - val_loss: 0.1148 - val_mae: 0.2770\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0224 - mae: 0.1142 - val_loss: 0.1333 - val_mae: 0.3017\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0208 - mae: 0.1101 - val_loss: 0.1018 - val_mae: 0.2575\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0201 - mae: 0.1083 - val_loss: 0.1054 - val_mae: 0.2683\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0200 - mae: 0.1085 - val_loss: 0.0898 - val_mae: 0.2427\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0187 - mae: 0.1047 - val_loss: 0.1239 - val_mae: 0.2878\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0185 - mae: 0.1041 - val_loss: 0.1274 - val_mae: 0.2974\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0181 - mae: 0.1028 - val_loss: 0.1666 - val_mae: 0.3315\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0176 - mae: 0.1016 - val_loss: 0.1121 - val_mae: 0.2806\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0175 - mae: 0.1011 - val_loss: 0.1370 - val_mae: 0.2999\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0194 - mae: 0.1065 - val_loss: 0.1191 - val_mae: 0.2869\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0183 - mae: 0.1036 - val_loss: 0.1247 - val_mae: 0.2897\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0346 - mae: 0.1411 - val_loss: 0.1390 - val_mae: 0.3053\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0324 - mae: 0.1381 - val_loss: 0.1183 - val_mae: 0.2735\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0256 - mae: 0.1216 - val_loss: 0.1276 - val_mae: 0.2943\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.0218 - mae: 0.1118 - val_loss: 0.1066 - val_mae: 0.2589\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0222 - mae: 0.1127 - val_loss: 0.1364 - val_mae: 0.3013\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0199 - mae: 0.1071 - val_loss: 0.1022 - val_mae: 0.2561\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.0215 - mae: 0.1115 - val_loss: 0.1267 - val_mae: 0.2928\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0250 - mae: 0.1197 - val_loss: 0.1630 - val_mae: 0.3214\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0214 - mae: 0.1104 - val_loss: 0.1735 - val_mae: 0.3394\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0193 - mae: 0.1054 - val_loss: 0.0943 - val_mae: 0.2517\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0257 - mae: 0.1215 - val_loss: 0.1598 - val_mae: 0.3208\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0276 - mae: 0.1260 - val_loss: 0.1432 - val_mae: 0.3126\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.0244 - mae: 0.1176 - val_loss: 0.1402 - val_mae: 0.3067\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0242 - mae: 0.1168 - val_loss: 0.1113 - val_mae: 0.2724\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0249 - mae: 0.1190 - val_loss: 0.1953 - val_mae: 0.3615\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0222 - mae: 0.1121 - val_loss: 0.1291 - val_mae: 0.2940\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0233 - mae: 0.1145 - val_loss: 0.1313 - val_mae: 0.2883\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0213 - mae: 0.1089 - val_loss: 0.1401 - val_mae: 0.3059\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0215 - mae: 0.1101 - val_loss: 0.0800 - val_mae: 0.2225\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0225 - mae: 0.1123 - val_loss: 0.0889 - val_mae: 0.2422\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0234 - mae: 0.1146 - val_loss: 0.1422 - val_mae: 0.3109\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0281 - mae: 0.1265 - val_loss: 0.1241 - val_mae: 0.2831\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0393 - mae: 0.1514 - val_loss: 0.0988 - val_mae: 0.2458\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0332 - mae: 0.1388 - val_loss: 0.0849 - val_mae: 0.2326\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0281 - mae: 0.1269 - val_loss: 0.0651 - val_mae: 0.1958\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.0251 - mae: 0.1191 - val_loss: 0.0758 - val_mae: 0.2047\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0226 - mae: 0.1126 - val_loss: 0.0502 - val_mae: 0.1698\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0220 - mae: 0.1112 - val_loss: 0.0916 - val_mae: 0.2437\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0243 - mae: 0.1175 - val_loss: 0.0928 - val_mae: 0.2321\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0223 - mae: 0.1117 - val_loss: 0.0923 - val_mae: 0.2422\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0255 - mae: 0.1206 - val_loss: 0.0766 - val_mae: 0.2196\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0233 - mae: 0.1144 - val_loss: 0.0966 - val_mae: 0.2435\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0229 - mae: 0.1130 - val_loss: 0.0907 - val_mae: 0.2402\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0221 - mae: 0.1112 - val_loss: 0.0828 - val_mae: 0.2246\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0410 - mae: 0.1556 - val_loss: 0.0728 - val_mae: 0.2161\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0297 - mae: 0.1293 - val_loss: 0.1021 - val_mae: 0.2575\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0260 - mae: 0.1207 - val_loss: 0.1024 - val_mae: 0.2561\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0266 - mae: 0.1224 - val_loss: 0.1177 - val_mae: 0.2791\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0256 - mae: 0.1204 - val_loss: 0.1108 - val_mae: 0.2537\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0252 - mae: 0.1185 - val_loss: 0.1312 - val_mae: 0.2874\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0260 - mae: 0.1209 - val_loss: 0.0770 - val_mae: 0.2223\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0238 - mae: 0.1150 - val_loss: 0.1313 - val_mae: 0.2926\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0383 - mae: 0.1472 - val_loss: 0.1408 - val_mae: 0.3082\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0379 - mae: 0.1482 - val_loss: 0.1436 - val_mae: 0.3105\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0353 - mae: 0.1424 - val_loss: 0.1214 - val_mae: 0.2814\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0364 - mae: 0.1445 - val_loss: 0.1322 - val_mae: 0.2956\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0358 - mae: 0.1434 - val_loss: 0.0563 - val_mae: 0.1835\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0291 - mae: 0.1281 - val_loss: 0.0925 - val_mae: 0.2321\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0380 - mae: 0.1488 - val_loss: 0.1086 - val_mae: 0.2694\n",
      "Epoch 81/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0315 - mae: 0.1341 - val_loss: 0.1338 - val_mae: 0.3004\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0274 - mae: 0.1242 - val_loss: 0.0857 - val_mae: 0.2294\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0280 - mae: 0.1261 - val_loss: 0.0690 - val_mae: 0.2033\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0281 - mae: 0.1259 - val_loss: 0.0923 - val_mae: 0.2572\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0268 - mae: 0.1224 - val_loss: 0.0687 - val_mae: 0.2038\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0286 - mae: 0.1269 - val_loss: 0.2241 - val_mae: 0.3881\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0293 - mae: 0.1288 - val_loss: 0.1392 - val_mae: 0.2991\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0294 - mae: 0.1286 - val_loss: 0.0963 - val_mae: 0.2529\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0308 - mae: 0.1325 - val_loss: 0.0816 - val_mae: 0.2253\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0279 - mae: 0.1255 - val_loss: 0.0752 - val_mae: 0.2144\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0288 - mae: 0.1275 - val_loss: 0.1059 - val_mae: 0.2652\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0267 - mae: 0.1217 - val_loss: 0.0885 - val_mae: 0.2393\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0273 - mae: 0.1234 - val_loss: 0.1190 - val_mae: 0.2865\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0261 - mae: 0.1208 - val_loss: 0.0779 - val_mae: 0.2152\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0267 - mae: 0.1220 - val_loss: 0.0929 - val_mae: 0.2391\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0304 - mae: 0.1312 - val_loss: 0.0899 - val_mae: 0.2338\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0262 - mae: 0.1211 - val_loss: 0.0935 - val_mae: 0.2419\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0277 - mae: 0.1248 - val_loss: 0.1432 - val_mae: 0.3099\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0258 - mae: 0.1211 - val_loss: 0.0844 - val_mae: 0.2275\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0250 - mae: 0.1181 - val_loss: 0.0848 - val_mae: 0.2312\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0254 - mae: 0.1189 - val_loss: 0.0710 - val_mae: 0.2065\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0300 - mae: 0.1301 - val_loss: 0.1572 - val_mae: 0.3229\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0377 - mae: 0.1477 - val_loss: 0.1373 - val_mae: 0.3029\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0329 - mae: 0.1370 - val_loss: 0.1206 - val_mae: 0.2801\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0312 - mae: 0.1324 - val_loss: 0.1250 - val_mae: 0.2883\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0314 - mae: 0.1333 - val_loss: 0.0768 - val_mae: 0.2165\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0260 - mae: 0.1209 - val_loss: 0.1296 - val_mae: 0.2896\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0278 - mae: 0.1246 - val_loss: 0.0816 - val_mae: 0.2286\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0287 - mae: 0.1267 - val_loss: 0.1476 - val_mae: 0.3101\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0321 - mae: 0.1349 - val_loss: 0.1325 - val_mae: 0.2964\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0281 - mae: 0.1252 - val_loss: 0.0347 - val_mae: 0.1408\n",
      "Epoch 112/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0257 - mae: 0.1199 - val_loss: 0.0834 - val_mae: 0.2251\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0240 - mae: 0.1154 - val_loss: 0.0527 - val_mae: 0.1735\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0244 - mae: 0.1157 - val_loss: 0.1263 - val_mae: 0.2891\n",
      "Epoch 115/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0301 - mae: 0.1304 - val_loss: 0.1415 - val_mae: 0.3052\n",
      "Epoch 116/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0288 - mae: 0.1273 - val_loss: 0.0894 - val_mae: 0.2362\n",
      "Epoch 117/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0251 - mae: 0.1186 - val_loss: 0.0796 - val_mae: 0.2202\n",
      "Epoch 118/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0247 - mae: 0.1169 - val_loss: 0.0786 - val_mae: 0.2241\n",
      "Epoch 119/500\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.0247 - mae: 0.1167 - val_loss: 0.0948 - val_mae: 0.2450\n",
      "Epoch 120/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0396 - mae: 0.1523 - val_loss: 0.0934 - val_mae: 0.2490\n",
      "Epoch 121/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0353 - mae: 0.1435 - val_loss: 0.2619 - val_mae: 0.3841\n",
      "Epoch 122/500\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.0293 - mae: 0.1290 - val_loss: 0.1353 - val_mae: 0.2993\n",
      "Epoch 123/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0311 - mae: 0.1332 - val_loss: 0.1844 - val_mae: 0.3496\n",
      "Epoch 124/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0359 - mae: 0.1441 - val_loss: 0.0999 - val_mae: 0.2554\n",
      "Epoch 125/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0360 - mae: 0.1447 - val_loss: 0.1278 - val_mae: 0.2920\n",
      "Epoch 126/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0301 - mae: 0.1309 - val_loss: 0.1361 - val_mae: 0.2936\n",
      "Epoch 127/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0268 - mae: 0.1230 - val_loss: 0.1031 - val_mae: 0.2475\n",
      "Epoch 128/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0264 - mae: 0.1217 - val_loss: 0.0901 - val_mae: 0.2342\n",
      "Epoch 129/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0248 - mae: 0.1179 - val_loss: 0.1180 - val_mae: 0.2769\n",
      "Epoch 130/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0295 - mae: 0.1293 - val_loss: 0.0763 - val_mae: 0.2175\n",
      "Epoch 131/500\n",
      "250/250 [==============================] - 16s 62ms/step - loss: 0.0271 - mae: 0.1235 - val_loss: 0.1005 - val_mae: 0.2614\n",
      "Epoch 132/500\n",
      "250/250 [==============================] - 15s 62ms/step - loss: 0.0296 - mae: 0.1289 - val_loss: 0.1343 - val_mae: 0.2984\n",
      "Epoch 133/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0260 - mae: 0.1206 - val_loss: 0.1066 - val_mae: 0.2610\n",
      "Epoch 134/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0233 - mae: 0.1137 - val_loss: 0.0478 - val_mae: 0.1654\n",
      "Epoch 135/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0219 - mae: 0.1097 - val_loss: 0.1039 - val_mae: 0.2502\n",
      "Epoch 136/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0327 - mae: 0.1359 - val_loss: 0.0567 - val_mae: 0.1823\n",
      "Epoch 137/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0274 - mae: 0.1238 - val_loss: 0.0934 - val_mae: 0.2388\n",
      "Epoch 138/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0259 - mae: 0.1206 - val_loss: 0.1031 - val_mae: 0.2596\n",
      "Epoch 139/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0247 - mae: 0.1174 - val_loss: 0.0932 - val_mae: 0.2330\n",
      "Epoch 140/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0228 - mae: 0.1123 - val_loss: 0.0738 - val_mae: 0.2042\n",
      "Epoch 141/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0221 - mae: 0.1110 - val_loss: 0.1741 - val_mae: 0.3389\n",
      "Epoch 142/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0243 - mae: 0.1167 - val_loss: 0.1110 - val_mae: 0.2715\n",
      "Epoch 143/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0224 - mae: 0.1113 - val_loss: 0.0410 - val_mae: 0.1527\n",
      "Epoch 144/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0249 - mae: 0.1176 - val_loss: 0.2046 - val_mae: 0.3662\n",
      "Epoch 145/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0228 - mae: 0.1130 - val_loss: 0.0759 - val_mae: 0.2102\n",
      "Epoch 146/500\n",
      "250/250 [==============================] - 16s 62ms/step - loss: 0.0259 - mae: 0.1200 - val_loss: 0.1312 - val_mae: 0.2838\n",
      "Epoch 147/500\n",
      "250/250 [==============================] - 15s 62ms/step - loss: 0.0244 - mae: 0.1165 - val_loss: 0.1020 - val_mae: 0.2398\n",
      "Epoch 148/500\n",
      "250/250 [==============================] - 15s 61ms/step - loss: 0.0288 - mae: 0.1263 - val_loss: 0.1072 - val_mae: 0.2661\n",
      "Epoch 149/500\n",
      "250/250 [==============================] - 16s 62ms/step - loss: 0.0290 - mae: 0.1275 - val_loss: 0.0965 - val_mae: 0.2415\n",
      "Epoch 150/500\n",
      "250/250 [==============================] - 15s 61ms/step - loss: 0.0424 - mae: 0.1563 - val_loss: 0.0812 - val_mae: 0.2290\n",
      "Epoch 151/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0397 - mae: 0.1523 - val_loss: 0.1045 - val_mae: 0.2696\n",
      "Epoch 152/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0388 - mae: 0.1501 - val_loss: 0.0958 - val_mae: 0.2382\n",
      "Epoch 153/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0347 - mae: 0.1406 - val_loss: 0.0711 - val_mae: 0.2070\n",
      "Epoch 154/500\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.0312 - mae: 0.1323 - val_loss: 0.0992 - val_mae: 0.2567\n",
      "Epoch 155/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0305 - mae: 0.1308 - val_loss: 0.1157 - val_mae: 0.2738\n",
      "Epoch 156/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0274 - mae: 0.1234 - val_loss: 0.0401 - val_mae: 0.1483\n",
      "Epoch 157/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0271 - mae: 0.1227 - val_loss: 0.0998 - val_mae: 0.2481\n",
      "Epoch 158/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0241 - mae: 0.1153 - val_loss: 0.0813 - val_mae: 0.2139\n",
      "Epoch 159/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0240 - mae: 0.1154 - val_loss: 0.0815 - val_mae: 0.2209\n",
      "Epoch 160/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0241 - mae: 0.1156 - val_loss: 0.1063 - val_mae: 0.2634\n",
      "Epoch 161/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0230 - mae: 0.1125 - val_loss: 0.1046 - val_mae: 0.2593\n",
      "Epoch 162/500\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.0237 - mae: 0.1145 - val_loss: 0.0954 - val_mae: 0.2450\n",
      "Epoch 163/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0294 - mae: 0.1286 - val_loss: 0.1219 - val_mae: 0.2883\n",
      "Epoch 164/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0277 - mae: 0.1253 - val_loss: 0.1127 - val_mae: 0.2665\n",
      "Epoch 165/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0310 - mae: 0.1324 - val_loss: 0.1104 - val_mae: 0.2709\n",
      "Epoch 166/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0270 - mae: 0.1231 - val_loss: 0.1263 - val_mae: 0.2907\n",
      "Epoch 167/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0279 - mae: 0.1256 - val_loss: 0.0885 - val_mae: 0.2391\n",
      "Epoch 168/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0290 - mae: 0.1282 - val_loss: 0.1012 - val_mae: 0.2469\n",
      "Epoch 169/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0258 - mae: 0.1196 - val_loss: 0.0657 - val_mae: 0.1981\n",
      "Epoch 170/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0273 - mae: 0.1238 - val_loss: 0.0554 - val_mae: 0.1808\n",
      "Epoch 171/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0251 - mae: 0.1181 - val_loss: 0.0833 - val_mae: 0.2296\n",
      "Epoch 172/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0264 - mae: 0.1218 - val_loss: 0.0878 - val_mae: 0.2344\n",
      "Epoch 173/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0292 - mae: 0.1286 - val_loss: 0.0818 - val_mae: 0.2306\n",
      "Epoch 174/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0269 - mae: 0.1226 - val_loss: 0.1061 - val_mae: 0.2587\n",
      "Epoch 175/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0264 - mae: 0.1212 - val_loss: 0.0546 - val_mae: 0.1774\n",
      "Epoch 176/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0275 - mae: 0.1233 - val_loss: 0.0804 - val_mae: 0.2259\n",
      "Epoch 177/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0420 - mae: 0.1567 - val_loss: 0.0832 - val_mae: 0.2276\n",
      "Epoch 178/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0391 - mae: 0.1513 - val_loss: 0.0780 - val_mae: 0.2176\n",
      "Epoch 179/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0362 - mae: 0.1444 - val_loss: 0.1060 - val_mae: 0.2675\n",
      "Epoch 180/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0328 - mae: 0.1361 - val_loss: 0.1215 - val_mae: 0.2757\n",
      "Epoch 181/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0308 - mae: 0.1312 - val_loss: 0.1145 - val_mae: 0.2665\n",
      "Epoch 182/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0278 - mae: 0.1241 - val_loss: 0.0750 - val_mae: 0.2084\n",
      "Epoch 183/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0267 - mae: 0.1211 - val_loss: 0.0460 - val_mae: 0.1616\n",
      "Epoch 184/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0266 - mae: 0.1215 - val_loss: 0.0918 - val_mae: 0.2362\n",
      "Epoch 185/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0278 - mae: 0.1245 - val_loss: 0.1286 - val_mae: 0.2860\n",
      "Epoch 186/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0263 - mae: 0.1206 - val_loss: 0.1082 - val_mae: 0.2620\n",
      "Epoch 187/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0272 - mae: 0.1228 - val_loss: 0.0436 - val_mae: 0.1552\n",
      "Epoch 188/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0262 - mae: 0.1201 - val_loss: 0.0653 - val_mae: 0.1951\n",
      "Epoch 189/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0256 - mae: 0.1188 - val_loss: 0.0967 - val_mae: 0.2456\n",
      "Epoch 190/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0243 - mae: 0.1162 - val_loss: 0.0802 - val_mae: 0.2193\n",
      "Epoch 191/500\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.0225 - mae: 0.1113 - val_loss: 0.0514 - val_mae: 0.1696\n",
      "Epoch 192/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0263 - mae: 0.1216 - val_loss: 0.0744 - val_mae: 0.2100\n",
      "Epoch 193/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0266 - mae: 0.1218 - val_loss: 0.0901 - val_mae: 0.2343\n",
      "Epoch 194/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0257 - mae: 0.1196 - val_loss: 0.0663 - val_mae: 0.2017\n",
      "Epoch 195/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0278 - mae: 0.1253 - val_loss: 0.0809 - val_mae: 0.2210\n",
      "Epoch 196/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0240 - mae: 0.1154 - val_loss: 0.1252 - val_mae: 0.2847\n",
      "Epoch 197/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0245 - mae: 0.1166 - val_loss: 0.1521 - val_mae: 0.3148\n",
      "Epoch 198/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0251 - mae: 0.1183 - val_loss: 0.0703 - val_mae: 0.2108\n",
      "Epoch 199/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0264 - mae: 0.1210 - val_loss: 0.0591 - val_mae: 0.1875\n",
      "Epoch 200/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0280 - mae: 0.1248 - val_loss: 0.1104 - val_mae: 0.2731\n",
      "Epoch 201/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0258 - mae: 0.1193 - val_loss: 0.0945 - val_mae: 0.2419\n",
      "Epoch 202/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0274 - mae: 0.1239 - val_loss: 0.0742 - val_mae: 0.2117\n",
      "Epoch 203/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0260 - mae: 0.1202 - val_loss: 0.0712 - val_mae: 0.2083\n",
      "Epoch 204/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0238 - mae: 0.1151 - val_loss: 0.1091 - val_mae: 0.2494\n",
      "Epoch 205/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0244 - mae: 0.1167 - val_loss: 0.0557 - val_mae: 0.1783\n",
      "Epoch 206/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0233 - mae: 0.1133 - val_loss: 0.0860 - val_mae: 0.2318\n",
      "Epoch 207/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0252 - mae: 0.1183 - val_loss: 0.0978 - val_mae: 0.2476\n",
      "Epoch 208/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0259 - mae: 0.1202 - val_loss: 0.1162 - val_mae: 0.2742\n",
      "Epoch 209/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0265 - mae: 0.1210 - val_loss: 0.1392 - val_mae: 0.3055\n",
      "Epoch 210/500\n",
      "250/250 [==============================] - 16s 66ms/step - loss: 0.0257 - mae: 0.1192 - val_loss: 0.0458 - val_mae: 0.1574\n",
      "Epoch 211/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0234 - mae: 0.1135 - val_loss: 0.0848 - val_mae: 0.2240\n",
      "Epoch 212/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0235 - mae: 0.1140 - val_loss: 0.0503 - val_mae: 0.1717\n",
      "Epoch 213/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0230 - mae: 0.1126 - val_loss: 0.0584 - val_mae: 0.1769\n",
      "Epoch 214/500\n",
      "250/250 [==============================] - 17s 66ms/step - loss: 0.0228 - mae: 0.1120 - val_loss: 0.0755 - val_mae: 0.2151\n",
      "Epoch 215/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0220 - mae: 0.1096 - val_loss: 0.0790 - val_mae: 0.2201\n",
      "Epoch 216/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0223 - mae: 0.1107 - val_loss: 0.0682 - val_mae: 0.2040\n",
      "Epoch 217/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0215 - mae: 0.1088 - val_loss: 0.0957 - val_mae: 0.2424\n",
      "Epoch 218/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0228 - mae: 0.1118 - val_loss: 0.1203 - val_mae: 0.2873\n",
      "Epoch 219/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0251 - mae: 0.1177 - val_loss: 0.0793 - val_mae: 0.2145\n",
      "Epoch 220/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0266 - mae: 0.1209 - val_loss: 0.0945 - val_mae: 0.2400\n",
      "Epoch 221/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0257 - mae: 0.1198 - val_loss: 0.0639 - val_mae: 0.1955\n",
      "Epoch 222/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0276 - mae: 0.1236 - val_loss: 0.0809 - val_mae: 0.2268\n",
      "Epoch 223/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0304 - mae: 0.1310 - val_loss: 0.0593 - val_mae: 0.1801\n",
      "Epoch 224/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0309 - mae: 0.1323 - val_loss: 0.1310 - val_mae: 0.2941\n",
      "Epoch 225/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0300 - mae: 0.1299 - val_loss: 0.1827 - val_mae: 0.3425\n",
      "Epoch 226/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0271 - mae: 0.1231 - val_loss: 0.1900 - val_mae: 0.3435\n",
      "Epoch 227/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0255 - mae: 0.1186 - val_loss: 0.1283 - val_mae: 0.2846\n",
      "Epoch 228/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0250 - mae: 0.1173 - val_loss: 0.0396 - val_mae: 0.1500\n",
      "Epoch 229/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0255 - mae: 0.1189 - val_loss: 0.1254 - val_mae: 0.2822\n",
      "Epoch 230/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0226 - mae: 0.1112 - val_loss: 0.0613 - val_mae: 0.1882\n",
      "Epoch 231/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0228 - mae: 0.1121 - val_loss: 0.0442 - val_mae: 0.1600\n",
      "Epoch 232/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0224 - mae: 0.1105 - val_loss: 0.0612 - val_mae: 0.1876\n",
      "Epoch 233/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0217 - mae: 0.1083 - val_loss: 0.0551 - val_mae: 0.1763\n",
      "Epoch 234/500\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.0251 - mae: 0.1179 - val_loss: 0.1962 - val_mae: 0.3620\n",
      "Epoch 235/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0219 - mae: 0.1101 - val_loss: 0.0665 - val_mae: 0.2000\n",
      "Epoch 236/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0219 - mae: 0.1092 - val_loss: 0.0429 - val_mae: 0.1562\n",
      "Epoch 237/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0222 - mae: 0.1102 - val_loss: 0.0965 - val_mae: 0.2532\n",
      "Epoch 238/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0240 - mae: 0.1148 - val_loss: 0.0502 - val_mae: 0.1667\n",
      "Epoch 239/500\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.0245 - mae: 0.1166 - val_loss: 0.1171 - val_mae: 0.2733\n",
      "Epoch 240/500\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.0231 - mae: 0.1123 - val_loss: 0.1292 - val_mae: 0.2900\n",
      "Epoch 241/500\n",
      "250/250 [==============================] - 15s 60ms/step - loss: 0.0217 - mae: 0.1086 - val_loss: 0.1107 - val_mae: 0.2699\n",
      "Epoch 242/500\n",
      "250/250 [==============================] - 14s 58ms/step - loss: 0.0210 - mae: 0.1067 - val_loss: 0.0788 - val_mae: 0.2175\n",
      "Epoch 243/500\n",
      "250/250 [==============================] - 14s 57ms/step - loss: 0.0240 - mae: 0.1148 - val_loss: 0.0735 - val_mae: 0.2102\n",
      "Epoch 244/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0233 - mae: 0.1132 - val_loss: 0.0687 - val_mae: 0.2038\n",
      "Epoch 245/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0224 - mae: 0.1108 - val_loss: 0.0685 - val_mae: 0.1991\n",
      "Epoch 246/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0217 - mae: 0.1087 - val_loss: 0.0651 - val_mae: 0.1927\n",
      "Epoch 247/500\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0200 - mae: 0.1047 - val_loss: 0.0743 - val_mae: 0.2095\n",
      "Epoch 248/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0252 - mae: 0.1177 - val_loss: 0.1204 - val_mae: 0.2815\n",
      "Epoch 249/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0265 - mae: 0.1226 - val_loss: 0.1161 - val_mae: 0.2730\n",
      "Epoch 250/500\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0224 - mae: 0.1115 - val_loss: 0.0496 - val_mae: 0.1709\n",
      "Epoch 251/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0272 - mae: 0.1235 - val_loss: 0.0935 - val_mae: 0.2475\n",
      "Epoch 252/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0274 - mae: 0.1237 - val_loss: 0.1129 - val_mae: 0.2615\n",
      "Epoch 253/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0280 - mae: 0.1251 - val_loss: 0.0613 - val_mae: 0.1947\n",
      "Epoch 254/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0298 - mae: 0.1296 - val_loss: 0.0689 - val_mae: 0.2070\n",
      "Epoch 255/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0268 - mae: 0.1221 - val_loss: 0.0781 - val_mae: 0.2131\n",
      "Epoch 256/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0252 - mae: 0.1180 - val_loss: 0.0732 - val_mae: 0.2026\n",
      "Epoch 257/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0248 - mae: 0.1168 - val_loss: 0.0782 - val_mae: 0.2169\n",
      "Epoch 258/500\n",
      "250/250 [==============================] - 14s 57ms/step - loss: 0.0285 - mae: 0.1261 - val_loss: 0.1002 - val_mae: 0.2486\n",
      "Epoch 259/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0333 - mae: 0.1373 - val_loss: 0.0837 - val_mae: 0.2326\n",
      "Epoch 260/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0303 - mae: 0.1306 - val_loss: 0.0748 - val_mae: 0.2114\n",
      "Epoch 261/500\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0271 - mae: 0.1233 - val_loss: 0.0794 - val_mae: 0.2209\n",
      "Epoch 262/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0253 - mae: 0.1184 - val_loss: 0.0244 - val_mae: 0.1122\n",
      "Epoch 263/500\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0245 - mae: 0.1168 - val_loss: 0.0761 - val_mae: 0.2079\n",
      "Epoch 264/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0251 - mae: 0.1178 - val_loss: 0.0984 - val_mae: 0.2444\n",
      "Epoch 265/500\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0295 - mae: 0.1293 - val_loss: 0.0867 - val_mae: 0.2355\n",
      "Epoch 266/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0272 - mae: 0.1234 - val_loss: 0.0541 - val_mae: 0.1721\n",
      "Epoch 267/500\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0244 - mae: 0.1163 - val_loss: 0.0593 - val_mae: 0.1800\n",
      "Epoch 268/500\n",
      "250/250 [==============================] - 14s 57ms/step - loss: 0.0230 - mae: 0.1128 - val_loss: 0.0660 - val_mae: 0.1967\n",
      "Epoch 269/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0221 - mae: 0.1104 - val_loss: 0.0302 - val_mae: 0.1263\n",
      "Epoch 270/500\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0218 - mae: 0.1096 - val_loss: 0.0710 - val_mae: 0.2002\n",
      "Epoch 271/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0222 - mae: 0.1102 - val_loss: 0.1102 - val_mae: 0.2660\n",
      "Epoch 272/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0223 - mae: 0.1102 - val_loss: 0.0346 - val_mae: 0.1367\n",
      "Epoch 273/500\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0225 - mae: 0.1112 - val_loss: 0.1032 - val_mae: 0.2488\n",
      "Epoch 274/500\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0215 - mae: 0.1085 - val_loss: 0.0818 - val_mae: 0.2168\n",
      "Epoch 275/500\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0206 - mae: 0.1062 - val_loss: 0.0811 - val_mae: 0.2150\n",
      "Epoch 276/500\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0209 - mae: 0.1073 - val_loss: 0.0540 - val_mae: 0.1750\n",
      "Epoch 277/500\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0222 - mae: 0.1109 - val_loss: 0.0808 - val_mae: 0.2211\n",
      "Epoch 278/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0239 - mae: 0.1155 - val_loss: 0.1342 - val_mae: 0.2936\n",
      "Epoch 279/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0229 - mae: 0.1124 - val_loss: 0.0780 - val_mae: 0.2109\n",
      "Epoch 280/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0225 - mae: 0.1114 - val_loss: 0.1106 - val_mae: 0.2659\n",
      "Epoch 281/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0232 - mae: 0.1130 - val_loss: 0.0928 - val_mae: 0.2452\n",
      "Epoch 282/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0315 - mae: 0.1336 - val_loss: 0.4225 - val_mae: 0.4746\n",
      "Epoch 283/500\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0269 - mae: 0.1228 - val_loss: 0.1128 - val_mae: 0.2358\n",
      "Epoch 284/500\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0306 - mae: 0.1314 - val_loss: 0.0585 - val_mae: 0.1869\n",
      "Epoch 285/500\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0311 - mae: 0.1332 - val_loss: 0.0805 - val_mae: 0.2194\n",
      "Epoch 286/500\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0283 - mae: 0.1260 - val_loss: 0.1069 - val_mae: 0.2158\n",
      "Epoch 287/500\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0262 - mae: 0.1211 - val_loss: 0.0820 - val_mae: 0.2230\n",
      "Epoch 288/500\n",
      "250/250 [==============================] - 13s 50ms/step - loss: 0.0307 - mae: 0.1314 - val_loss: 0.0506 - val_mae: 0.1705\n",
      "Epoch 289/500\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0278 - mae: 0.1245 - val_loss: 0.0551 - val_mae: 0.1803\n",
      "Epoch 290/500\n",
      "163/250 [==================>...........] - ETA: 4s - loss: 0.0261 - mae: 0.1203"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m use_trained \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m,\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m trainable \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m,\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m----> 7\u001b[0m         model,history \u001b[39m=\u001b[39m objective(use_trained)\n\u001b[0;32m      8\u001b[0m         model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m0121Project/model_\u001b[39m\u001b[39m{\u001b[39;00mCNN_size\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00muse_trained\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtrainable\u001b[39m}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m         history_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(history\u001b[39m.\u001b[39mhistory)\n",
      "Cell \u001b[1;32mIn[47], line 52\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(use_pretrained, CNN_size, trainable)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(use_pretrained\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, CNN_size\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     51\u001b[0m     model \u001b[39m=\u001b[39m create_model(use_pretrained, CNN_size, trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 52\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     53\u001b[0m         x_train,\n\u001b[0;32m     54\u001b[0m         y_train,\n\u001b[0;32m     55\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[0;32m     56\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m     57\u001b[0m         validation_data\u001b[39m=\u001b[39;49m(x_test, y_test),\n\u001b[0;32m     58\u001b[0m     )\n\u001b[0;32m     59\u001b[0m     \u001b[39m#学習の様子をプロット\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Dette\\.virtualenvs\\python-fluid-python3-_nSsHetM\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# model,history = objective()\n",
    "# model2,history2 = objective(True)#use_pretrained\n",
    "\n",
    "for CNN_size in range(8):\n",
    "    for use_trained in (True,False):\n",
    "        for trainable in (True,False):\n",
    "            model,history = objective(use_trained)\n",
    "            model.save(f\"0121Project/model_{CNN_size}_{use_trained}_{trainable}.h5\")\n",
    "            history_df = pd.DataFrame(history.history)\n",
    "            history_df.to_csv(f\"0121Project/history_{CNN_size}_{use_trained}_{trainable}.csv\")\n",
    "            #メモリ解放\n",
    "            del model\n",
    "            del history\n",
    "            del history_df\n",
    "            # メモリ使用量の確認\n",
    "            print(\"memory usage: \", psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024, \"MB\")\n",
    "            filename = f\"0121Project/plot_{CNN_size}_{use_trained}_{trainable}.png\"\n",
    "            print(filename)\n",
    "            plot_and_save(history,filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-fluid-python3-_nSsHetM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c7e84feb875d0a630bed22fa394cb9e9d77c800863796b67237a2f1657097b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
